{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "CgTWcHTrY9of",
        "g-u8xgowbghp",
        "cP4zLzvMaQCa",
        "78L4q77BZsFm",
        "oYz-8xgLwwmq",
        "K37h67CIyka_"
      ],
      "mount_file_id": "1GdLrvsHlgsWHgqCke6Q1TvXs-ogijJB8",
      "authorship_tag": "ABX9TyNjXYwZ/2m/CwR6zNEomkQO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShuqairABD/ResNet-152/blob/main/ResNet_152_Liza_Alert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **start**"
      ],
      "metadata": {
        "id": "CgTWcHTrY9of"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sa6bsetprLTd",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, Subset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "import albumentations as A\n",
        "from torchvision.transforms import v2\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import PIL\n",
        "from pathlib import Path\n",
        "import os\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import copy\n",
        "from torchsummary import summary\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "import random\n",
        "import pandas as pd\n",
        "import pprint\n",
        "from tabulate import tabulate\n",
        "\n",
        "import torchvision.models as models\n",
        "from torch.optim import Adam\n",
        "from torchvision.models import resnet50\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "\n",
        "from torchvision import models, transforms, datasets\n",
        "\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "from torch.optim.lr_scheduler import StepLR\n"
      ],
      "metadata": {
        "id": "n3xpDIgyrVT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resize images (при необходимости)"
      ],
      "metadata": {
        "id": "g-u8xgowbghp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def resize_images(input_dir, output_dir, target_size):\n",
        "#     # Создание каталога для выходных изображений, если он не существует\n",
        "#     os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "#     # Итерация по каждому подкаталогу (папке класса) во входном каталоге\n",
        "#     for root, _, files in os.walk(input_dir):\n",
        "#         for file in files:\n",
        "#             # Проверка, является ли файл файлом изображения\n",
        "#             if file.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif')):\n",
        "#                 # Составление путей к файлам ввода и вывода\n",
        "#                 input_path = os.path.join(root, file)\n",
        "#                 output_path = os.path.join(output_dir, os.path.relpath(input_path, input_dir))\n",
        "\n",
        "#                 # Создание каталогов для пути к выходному файлу, если необходимо\n",
        "#                 os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "\n",
        "#                 # Открытие изображения\n",
        "#                 with Image.open(input_path) as img:\n",
        "#                     # Изменение размера изображения\n",
        "#                     img_resized = img.resize(target_size, Image.ANTIALIAS)\n",
        "\n",
        "#                     # Сохранение измененного изображения\n",
        "#                     img_resized.save(output_path)\n",
        "\n",
        "\n",
        "# input_directory = '/content/drive/MyDrive/WEATHER'  # # каталог, содержащий исходные изображения\n",
        "# output_directory = '/content/resiezed_images'  # каталог, в котором будут сохранены измененные изображения\n",
        "# target_image_size = (640, 640)  #  целевой размер для измененных изображений\n",
        "\n",
        "# # Изменение размера изображений\n",
        "# resize_images(input_directory, output_directory, target_image_size)\n",
        "\n",
        "# print(\"Image resizing complete.\")\n"
      ],
      "metadata": {
        "id": "6Fl4wt5hbo0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def resize_images(input_folder, output_folder, target_size):\n",
        "#   max_width = target_size[0]\n",
        "#   max_height = target_size[0]\n",
        "#   max_ratio = max_width / max_height\n",
        "#   color = 3\n",
        "#   for root, dirs, files in os.walk(input_folder):\n",
        "#     for file_name in files:\n",
        "#       try:\n",
        "#           # Составляем полный путь к входному файлу\n",
        "#           input_path = os.path.join(root, file_name)\n",
        "#           output_path = os.path.join(output_folder, os.path.relpath(input_path, input_folder))\n",
        "#           os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "#           img_file_out = output_path\n",
        "#           img = Image.open(input_path)\n",
        "#           width = img.size[0]\n",
        "#           height = img.size[1]\n",
        "#           if width >= height * max_ratio:\n",
        "#             ratio = width/height\n",
        "#             w = max_width\n",
        "#             h = int(w / ratio)\n",
        "#             if h % 2 >= 1:\n",
        "#               h += 1\n",
        "#             img_1 = Image.open(input_path).resize((int(w), int(h)))\n",
        "#             img_2 = np.array(img_1)\n",
        "#             zero = np.zeros((int(max_height),int(max_width) ,color))\n",
        "#             x1 = int((max_height - h)/2)\n",
        "#             x2 = int(max_height  - x1)\n",
        "#             zero[x1:x2, :, :] = zero[x1:x2, :, :] + img_2\n",
        "#             zero = zero.astype(np.uint8)\n",
        "#             im = Image.fromarray(zero)\n",
        "# #            print(f'Разрешение файла {file_name} = {img.size}')\n",
        "# #            print(f'Разрешение измененного файла = {im.size}')\n",
        "#             im.save(f'{img_file_out}')\n",
        "#           elif width < height * max_ratio:\n",
        "#             ratio = width/height\n",
        "#             h = max_height\n",
        "#             w = int(h * ratio)\n",
        "#             if w % 2 >= 1:\n",
        "#               w += 1\n",
        "#             img_1 = Image.open(input_path).resize((int(w), int(h)))\n",
        "#             img_2 = np.array(img_1)\n",
        "#             zero = np.zeros((int(max_height),int(max_width) ,color))\n",
        "#             x1 = int((max_width - w)/2)\n",
        "#             x2 = int(max_width  - x1)\n",
        "#             zero[:, x1:x2, :] = zero[:, x1:x2, :] + img_2\n",
        "#             zero = zero.astype(np.uint8)\n",
        "#             im = Image.fromarray(zero)\n",
        "# #            print(f'Разрешение файла {file_name} = {img.size}')\n",
        "# #            print(f'Разрешение измененного файла = {im.size}')\n",
        "#             im.save(f'{img_file_out}')\n",
        "#       except Exception as e:\n",
        "#           print(f\"Ошибка при обработке {file_name}: {str(e)}\")\n",
        "\n",
        "\n",
        "# input_directory = '/content/drive/MyDrive/WEATHER'  # # каталог, содержащий исходные изображения\n",
        "# output_directory = '/content/resiezed_images'  # каталог, в котором будут сохранены измененные изображения\n",
        "# target_image_size = (640, 640)  #  целевой размер для измененных изображений\n",
        "\n",
        "# # Изменение размера изображений\n",
        "# resize_images(input_directory, output_directory, target_image_size)\n",
        "\n",
        "# print(\"Image resizing complete.\")"
      ],
      "metadata": {
        "id": "eRClXe6eb0x1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Глобальные переменные"
      ],
      "metadata": {
        "id": "OQG_YuVnZGpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# path\n",
        "data_dir = '/content/drive/MyDrive/WEATHER'\n",
        "save_weights_logs_dir = '/content/weights'\n",
        "\n",
        "\n",
        "if not os.path.exists(save_weights_logs_dir):\n",
        "    os.makedirs(save_weights_logs_dir)\n",
        "print(f\"Weights will be saved in: {save_weights_logs_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gl88t6H3wQ6-",
        "outputId": "9197f78e-0921-4d01-af84-63654a78df4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights will be saved in: /content/weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8eoQop84AQMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Подготовка датасета"
      ],
      "metadata": {
        "id": "OXu1lYG1ZW13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# transformation\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomCrop(224, padding=20),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load dataset\n",
        "dataset = ImageFolder(data_dir, transform=train_transform)\n",
        "\n",
        "\n",
        "test_split = 0.2\n",
        "batch_size = 64\n",
        "\n",
        "# size\n",
        "test_size = int(test_split * len(dataset))\n",
        "train_size = len(dataset) - test_size\n",
        "\n",
        "\n",
        "indices = list(range(len(dataset)))\n",
        "np.random.shuffle(indices)\n",
        "train_indices, test_indices = indices[:train_size], indices[train_size:]\n",
        "\n",
        "\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "test_sampler = SubsetRandomSampler(test_indices)\n",
        "\n",
        "\n",
        "train_dataloader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "test_dataloader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)\n",
        "\n",
        "dataloaders = {'train': train_dataloader, 'val': test_dataloader}\n"
      ],
      "metadata": {
        "id": "kJArJ6r0wUK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Main model**"
      ],
      "metadata": {
        "id": "cP4zLzvMaQCa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Модель ResNet-152"
      ],
      "metadata": {
        "id": "59p84vhDZh2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load  ResNet-152 with pre-trained weights\n",
        "model = models.resnet152(weights=models.ResNet152_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# exit Sigmoid\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 128),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Linear(128, 1),\n",
        "    nn.Sigmoid()\n",
        ").to(device)\n",
        "\n",
        "\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "id": "ZQccqdaiwhbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training (main model)"
      ],
      "metadata": {
        "id": "78L4q77BZsFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "8twklHDL5Wth",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29f34fb9-e445-4c8c-c8e5-948db5404ad9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model_training(num_epochs, model, dataloaders, criterion, optimizer, scheduler, save_weights_logs_dir, model_name='resnet152', device='cuda'):\n",
        "    train_loss_history = []\n",
        "    train_acc_history = []\n",
        "    val_acc_history = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(\"=================\")\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        print(\"=================\")\n",
        "\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0\n",
        "\n",
        "        for images, labels in dataloaders['train']:\n",
        "            images, labels = images.to(device), labels.to(device).float().view(-1, 1)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            correct_predictions += ((outputs > 0.5).float() == labels).sum().item()\n",
        "            total_predictions += labels.size(0)\n",
        "\n",
        "        epoch_train_loss = running_loss / len(dataloaders['train'].dataset)\n",
        "        epoch_train_acc = correct_predictions / total_predictions\n",
        "\n",
        "        print(f\"Train loss: {epoch_train_loss:.4f}, Train accuracy: {epoch_train_acc:.4f}\")\n",
        "        train_loss_history.append(epoch_train_loss)\n",
        "        train_acc_history.append(epoch_train_acc)\n",
        "\n",
        "        model.eval()\n",
        "        val_correct_predictions = 0\n",
        "        val_total_predictions = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for val_images, val_labels in dataloaders['val']:\n",
        "                val_images, val_labels = val_images.to(device), val_labels.to(device).float().view(-1, 1)\n",
        "                val_outputs = model(val_images)\n",
        "                val_correct_predictions += ((val_outputs > 0.5).float() == val_labels).sum().item()\n",
        "                val_total_predictions += val_labels.size(0)\n",
        "\n",
        "        epoch_val_acc = val_correct_predictions / val_total_predictions\n",
        "        val_acc_history.append(epoch_val_acc)\n",
        "\n",
        "        print(f\"Validation accuracy: {epoch_val_acc:.4f}\")\n",
        "        scheduler.step()\n",
        "\n",
        "        save_path = f\"{save_weights_logs_dir}/{model_name}_epoch_{epoch+1}.pth\"\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "\n",
        "    return save_path, (train_loss_history, train_acc_history, val_acc_history)\n"
      ],
      "metadata": {
        "id": "x4fa7DxawlBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[25, 40], gamma=0.1)\n",
        "criterion = torch.nn.BCELoss()\n"
      ],
      "metadata": {
        "id": "GhDb216iwpYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 20\n",
        "print(\"Starting training...\")\n",
        "save_path, _ = model_training(num_epochs, model, dataloaders, criterion, optimizer, scheduler, save_weights_logs_dir, model_name='resnet152', device=device)\n",
        "print(\"Training complete.\")\n",
        "print(f\"Model weights saved to: {save_path}\")\n"
      ],
      "metadata": {
        "id": "KNed6YnJwr3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test main model"
      ],
      "metadata": {
        "id": "oYz-8xgLwwmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "kJKPAzvqs0Q6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet152(weights=None)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 128),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Linear(128, 1),\n",
        "    nn.Sigmoid()\n",
        ").to(device)\n",
        "\n",
        "# pretrained weights\n",
        "model_path = '/content/weights/resnet152_epoch_20.pth'\n",
        "model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "model.to(device)\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "8tJjV7hgs4UY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n"
      ],
      "metadata": {
        "id": "7kew4-pjs95-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_mapping = {'Cold_season': 0, 'Warm_season': 1}\n"
      ],
      "metadata": {
        "id": "lbYlc20atA52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms, models\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/test_images'\n",
        "\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "\n",
        "        image_path = os.path.join(folder_path, filename)\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        input_image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(input_image)\n",
        "\n",
        "\n",
        "        predicted = (output > 0.5).float()  # For binary classification\n",
        "\n",
        "        # class name\n",
        "        predicted_label = predicted.item()\n",
        "        predicted_class_name = list(label_mapping.keys())[list(label_mapping.values()).index(int(predicted_label))]\n",
        "\n",
        "\n",
        "        print(f\"Predicted class name for {filename}: {predicted_class_name}\")\n",
        "\n",
        "\n",
        "        plt.imshow(image)\n",
        "        plt.title(f\"Predicted class: {predicted_class_name}\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "a87ayfELtFLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**weights download**"
      ],
      "metadata": {
        "id": "qmCJRbr9Lx7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "folder_path = '/content/weights'\n",
        "zip_path = '/content/weights.zip'\n",
        "\n",
        "shutil.make_archive(zip_path.replace('.zip', ''), 'zip', folder_path)\n",
        "\n",
        "files.download(zip_path)\n"
      ],
      "metadata": {
        "id": "Wvi-UkQGwU2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **pre_train model**"
      ],
      "metadata": {
        "id": "K37h67CIyka_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### pre-train model"
      ],
      "metadata": {
        "id": "gNvgvdi4QL7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNALQ0nvSEcc",
        "outputId": "13f19b82-9b8f-4910-c325-bbd752200017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "_K2P4-ZBytOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet152(weights=None)\n",
        "\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 128),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Linear(128, 1),\n",
        "    nn.Sigmoid()\n",
        ").to(device)\n",
        "\n",
        "# fine-tuned weights\n",
        "model_path = '/content/drive/MyDrive/fine_tuned4_resnet152.pth'\n",
        "model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/WEATHER'\n",
        "dataset = ImageFolder(data_dir, transform=transform)\n",
        "\n",
        "test_split = 0.2\n",
        "batch_size = 64\n",
        "\n",
        "test_size = int(test_split * len(dataset))\n",
        "train_size = len(dataset) - test_size\n",
        "\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "dataloaders = {'train': train_dataloader, 'val': test_dataloader}\n",
        "\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = Adam(model.parameters(), lr=0.008)\n",
        "scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zkdvG39hyrzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(num_epochs, model, dataloaders, criterion, optimizer, scheduler, save_path, device):\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        print('-' * 10)\n",
        "\n",
        "\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iteration\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device).float().unsqueeze(1)  # форма для BCELoss\n",
        "\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    preds = (outputs > 0.5).float()\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # Backward + optimize (Обратная оптимизация)\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f'Model saved to {save_path}')\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "save_path = '/content/pretrained_5/new_fine_tuned5_resnet152.pth'\n"
      ],
      "metadata": {
        "id": "TLAW5qhWy46K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30\n",
        "trained_model = train_model(num_epochs, model, dataloaders, criterion, optimizer, scheduler, save_path, device)\n"
      ],
      "metadata": {
        "id": "CDVCkW1LBk2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oUFt9AVucSre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **save weights to drive**"
      ],
      "metadata": {
        "id": "g2AMhXPfcEt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Копирование файла весов в Google Drive\n",
        "!cp /content/pretrained_5/new_fine_tuned5_resnet152.pth /content/drive/MyDrive/new_fine_tuned5_resnet152.pth\n",
        "\n",
        "# Проверка наличия файла в Google Drive\n",
        "!ls /content/drive/MyDrive/\n",
        "\n",
        "# Проверка размера файла в Google Drive\n",
        "!ls -lh /content/pretrained_5/new_fine_tuned5_resnet152.pth\n",
        "\n",
        "# Проверка размера исходного файла в Colab\n",
        "!ls -lh /content/pretrained_5/new_fine_tuned5_resnet152.pth\n",
        "\n"
      ],
      "metadata": {
        "id": "ijDr4_2gcDg_",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test pre-trained model"
      ],
      "metadata": {
        "id": "edv_k8NsANTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# model architecture\n",
        "model = models.resnet152(weights=None)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 128),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Linear(128, 1),\n",
        "    nn.Sigmoid()\n",
        ").to(device)\n",
        "\n",
        "# Load the fine-tuned weights\n",
        "model_path = '/content/drive/MyDrive/fine_tuned5_resnet152.pth'\n",
        "model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "label_mapping = {'Cold_season': 0, 'Warm_season': 1}\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/test_images'\n",
        "\n",
        "def test_model(model, transform, label_mapping, folder_path, device):\n",
        "    model.eval()\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "\n",
        "            image_path = os.path.join(folder_path, filename)\n",
        "            image = Image.open(image_path).convert('RGB')\n",
        "            input_image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "\n",
        "            with torch.no_grad():\n",
        "                output = model(input_image)\n",
        "\n",
        "\n",
        "            predicted = (output > 0.5).float()  # For binary classification\n",
        "\n",
        "            # class name\n",
        "            predicted_label = predicted.item()\n",
        "            predicted_class_name = list(label_mapping.keys())[list(label_mapping.values()).index(int(predicted_label))]\n",
        "\n",
        "\n",
        "            print(f\"Predicted class name for {filename}: {predicted_class_name}\")\n",
        "\n",
        "\n",
        "            plt.imshow(image)\n",
        "            plt.title(f\"Predicted class: {predicted_class_name}\")\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "\n",
        "# Test\n",
        "test_model(model, transform, label_mapping, folder_path, device)\n"
      ],
      "metadata": {
        "id": "zX-voh4Zz-5S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}